spring:
  resources:
    chain:
      cache: false # 开发时使用，resource文件夹下的资源不进行缓存处理，即每次都需要去加载
  datasource:
    dynamic:
      primary: hive #设置默认的数据源或者数据源组,默认值即为master
      strict: false #设置严格模式,默认false不启动. 启动后再为匹配到指定数据源时候回抛出异常,不启动会使用默认数据源.
      datasource:
        hive:
          username: hadoop # 注意用户名，使用hive用户没操作hdfs的权限
          password: hadoop
          driver-class-name: org.apache.hive.jdbc.HiveDriver
          url: jdbc:hive2://hadoop04:10000/default
        hivemetadata:
          username: root
          password: root
          driver-class-name: com.mysql.jdbc.Driver
          url: jdbc:mysql://hadoop04:3306/hive?useUnicode=true&characterEncoding=utf-8&useSSL=false
        mysql_1:
          username: root
          password: root
          driver-class-name: com.mysql.jdbc.Driver
          url: jdbc:mysql://hadoop04:3306/sudu?useUnicode=true&characterEncoding=utf-8&useSSL=false
        mysql_2:
          username: root
          password: tse@9527
          driver-class-name: com.mysql.jdbc.Driver
          url: jdbc:mysql://localhost:3306/sudu?useUnicode=true&characterEncoding=utf-8&useSSL=false
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 10
      maximum-pool-size: 15
      auto-commit: true
      idle-timeout: 30000
      pool-name: ExpendHikariCP
      max-lifetime: 1800000
      connection-timeout: 30000
      connection-test-query: SELECT 1
  redis:
    host: localhost
    port: 6379
    database: 15
    jedis:
      pool:
        # 资源池中最大连接数
        # 默认8，-1表示无限制；可根据服务并发redis情况及服务端的支持上限调整
        max-active: 8
        # 资源池运行最大空闲的连接数
        # 默认8，-1表示无限制；可根据服务并发redis情况及服务端的支持上限调整，一般建议和max-active保持一致，避免资源伸缩带来的开销
        max-idle: 50
        # 当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)
        # 默认 -1 表示永不超时，设置5秒
        max-wait: 5000

server:
  port: 10024

logging:
  level:
    com.isacc.datax: debug
  file: logs/springboot_mybatis.log

mybatis:
  mapperLocations: classpath*:/mapper/*.xml
  configuration:
    mapUnderscoreToCamelCase: true

# 这里只要是路径，后面都加上/
datax:
  home: /usr/local/DataX/target/datax/datax/
  host: datax01
  port: 22
  # 要操作hdfs，用户要有权限
  username: hadoop
  password: hadoop
  basePackagePath: /templates/
  uploadDicPath: /home/hadoop/datax/
  localDicPath: src/main/datax/
  mysql2hive:
    whereTemplate: mysql2hive_where.ftl
    querySqlTemplate: mysql2hive_querySql.ftl
  hive2hive:
    template: hive2hive.ftl

azkaban:
  host: ${AZKABAN_HOST:http://192.168.43.221:8081}
  username: ${AZKABAN_USERNAME:azkaban}
  password: ${AZKABAN_PASSWORD:azkaban}
  localDicPath: src/main/azkaban/
  dataxJob: src/main/resources/dataxJob.job
  dataxProperties: dataxParams.properties